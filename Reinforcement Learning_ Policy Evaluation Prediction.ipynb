{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd3ec985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645e901f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = ['Right','Left','Up','Down']\n",
    "S = list(range(16))\n",
    "R = -1\n",
    "P1=[]\n",
    "for s in S:\n",
    "    P = []\n",
    "    if not (s == 0 or s==15):\n",
    "        for a in A:\n",
    "            if a == A[0]:\n",
    "                \n",
    "                s_new = s+1\n",
    "            elif a == A[1]:\n",
    "                s_new = s-1\n",
    "            elif a == A[2]:\n",
    "                s_new = s -4\n",
    "            else:\n",
    "                s_new = s + 4\n",
    "\n",
    "            if (a == A[0] and s in [3,7,11,15] or\n",
    "                a == A[1] and s in [0,4,8,12] or \n",
    "                a == A[2] and s in [0,1,2,3] or \n",
    "                a == A[3] and s in [12,13,14,15]):\n",
    "                \n",
    "                pass\n",
    "            else:\n",
    "                item=[s_new,R,s,a]\n",
    "                if item[0]==15 or item[0]==0:\n",
    "                    item[1]=0\n",
    "                    \n",
    "                P.append(item)\n",
    "                \n",
    "    P1.append(P)\n",
    "\n",
    "\n",
    "P1.pop(0)\n",
    "P1.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0befcc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = len(P1)+2\n",
    "num_actions =4\n",
    "# Initialize the policy arbitrarily (uniform random policy)\n",
    "policy = [[1/4]*len(a) for a in P1 ]\n",
    "\n",
    "\n",
    "#policy = [1/4]* (states)\n",
    "V = [0] * (states)\n",
    "theta = .001\n",
    "gamma = 0.9\n",
    "    \n",
    "V[1:-1] = [random.random() for x in V[1:-1]]\n",
    "\n",
    "def policy_evaluation(policy,V, P1,gamma, theta):\n",
    "\n",
    "    \n",
    "    iteration = 0\n",
    "    while True:\n",
    "        i = 0\n",
    "        delta = 0\n",
    "        \n",
    "        for s0 in P1:\n",
    "            i+=1\n",
    "            v = V[i]\n",
    "            V[i] =sum([policy[P1.index(s0)][s0.index(x)]*(x[1]+gamma*V[x[0]]) for x in s0])\n",
    "         \n",
    "        delta = max(delta, abs(v- V[i]) )\n",
    "        if delta < theta:\n",
    "            break\n",
    "        #print(delta)\n",
    "      \n",
    "    return V\n",
    "        \n",
    "def policy_improvement(policy,V, P1,gamma):\n",
    "    policy_stable = True\n",
    "    for s in range(states):\n",
    "        if s == 0 or s == 15:  # Skip terminal states\n",
    "            continue\n",
    "            \n",
    "        old_action = np.argmax(policy[s-1])\n",
    "        action_values = [(x[1]+gamma*V[x[0]]) for x in P1[s-1]]\n",
    "        best_action = np.argmax(action_values)\n",
    "        policy[s-1] = [0] * len(action_values)\n",
    "        policy[s-1][best_action]=1\n",
    "        if old_action != best_action:\n",
    "            policy_stable = False\n",
    "    return policy, policy_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20798823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value function: [0, 0.0, -1.0, -1.9, 0.0, -1.0, -1.9, -1.0, -1.0, -1.9, -1.0, 0.0, -1.9, -1.0, 0.0, 0]\n",
      "Optimal policy: [[0, 1, 0], [0, 1, 0], [1, 0], [0, 1, 0], [0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 1], [1, 0], [1, 0, 0], [1, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# Policy iteration\n",
    "while True:\n",
    "    V = policy_evaluation(policy, V, P1, gamma, theta)\n",
    "    policy, policy_stable = policy_improvement(policy, V, P1, gamma)\n",
    "    if policy_stable:\n",
    "        break\n",
    "\n",
    "print(\"Optimal value function:\", V)\n",
    "print(\"Optimal policy:\", policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e23b6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_policy = []\n",
    "for s0 in P1:\n",
    "    a = []\n",
    "\n",
    "    for state1,reward,state0,action in s0:\n",
    "        a.append(round(V[state1],2))\n",
    "\n",
    "    set_actions_indices=[i for i,j in enumerate(a) if j==max(a)] \n",
    "    action_policy.append([s0[x][-1] for x in set_actions_indices])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8792d04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i,j in enumerate(a) if j==max(a)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7569355b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v_array=np.array(V).reshape(4,4)\n",
    "sns.heatmap(v_array,annot=True,fmt='.2f',cbar=False,lw=1,linecolor='black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb7a125f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : ['Left']\n",
      "2 : ['Left']\n",
      "3 : ['Left', 'Down']\n",
      "4 : ['Up']\n",
      "5 : ['Left', 'Up']\n",
      "6 : ['Right', 'Left', 'Up', 'Down']\n",
      "7 : ['Down']\n",
      "8 : ['Up']\n",
      "9 : ['Right', 'Left', 'Up', 'Down']\n",
      "10 : ['Right', 'Down']\n",
      "11 : ['Down']\n",
      "12 : ['Right', 'Up']\n",
      "13 : ['Right']\n",
      "14 : ['Right']\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for _ in action_policy:\n",
    "    i+=1\n",
    "    print(i,':',_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5005c220",
   "metadata": {},
   "source": [
    "# Confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3589f72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.855"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#v[1,1]\n",
    "\n",
    "1/4*((-1+v_array[1,0]*.9)+(-1+v_array[0,1]*.9)+(-1+v_array[2,1]*.9)+(-1+v_array[1,2]*.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fdecc86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#v[1,2]\n",
    "\n",
    "1/4*((-1+v_array[1,1]*.9)+(-1+v_array[1,3]*.9)+(-1+v_array[0,2]*.9)+(-1+v_array[2,2]*.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58493a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#v[3,1]\n",
    "\n",
    "1/4*((-1+v_array[3,0]*.9)+(-1+v_array[3,2]*.9)+(-1+v_array[2,1]*.9)+ 0) #(-1+v_array[2,2]*.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c369cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.95"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#v[0,1]\n",
    "\n",
    "1/4*((0 +v_array[0,0]*.9)+(-1+v_array[0,2]*.9)+(-1+v_array[1,1]*.9)+ 0) #(-1+v_array[2,2]*.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeaef99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, -1, 14, 'Up')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state1,reward,state0,action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a90ef28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.38"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "904b8299",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3187445248.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    ======================================================\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "======================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f9ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation1 = policy_evaluation(policy,V, P1,gamma, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf01fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_array=np.array(evaluation1).reshape(4,4)\n",
    "sns.heatmap(v_array,annot=True,fmt='.2f',cbar=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f95f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3306b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pi =1/4\n",
    "teta = 0.008065\n",
    "V = [0]*16\n",
    "gamma =.9\n",
    "\n",
    "for i in range(len(P1)):\n",
    "    V[i+1]= random.random()\n",
    "\n",
    "while True:   \n",
    "    \n",
    "    error_difference = 0\n",
    "    \n",
    "    for s0 in range(len(P1)):\n",
    "        \n",
    "        v = V[s0+1]\n",
    "        \n",
    "        new_value = 0\n",
    "        \n",
    "        for state1,reward,state0,action in P1[s0]:  \n",
    "            \n",
    "            new_value+= pi*(reward+ gamma *V[state1])\n",
    "            \n",
    "        V[s0+1]=new_value  \n",
    "        \n",
    "        error_difference = max(error_difference,abs(v-V[s0+1]))\n",
    "    if error_difference < teta:\n",
    "        break\n",
    "    print(error_difference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b85b77f",
   "metadata": {},
   "source": [
    "========================================\n",
    "# MAZE with reward at state 4\n",
    "======================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d28cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_prob = np.array(np.zeros(400),dtype=int).reshape(25,4,4)\n",
    "transition_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ecff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S`,R,S,A\n",
    "i = 0\n",
    "transition_prob = np.array(np.zeros(400),dtype=int).reshape(25,4,4)\n",
    "\n",
    "for state in range(len(transition_prob)):\n",
    "    \n",
    "    transition_prob[state][:,2]=i\n",
    "    transition_prob[state][:,1]=-1\n",
    "    j=0\n",
    "    for action in transition_prob[state]:\n",
    "        action[3]=j\n",
    "        if state==4:\n",
    "            transition_prob[state][:,1]=0\n",
    "        if state==3 and action[3]==1:\n",
    "            transition_prob[state][1,1]=0\n",
    "            \n",
    "        j+=1\n",
    "    i+=1\n",
    "    transition_prob[state][:,0] = transition_prob[state][:,2]\n",
    "    \n",
    "    if state==0 or state ==9:\n",
    "        transition_prob[state][3][0]=transition_prob[state][3][2]+5\n",
    "    if state==1 or state==11 or state==21:\n",
    "        transition_prob[state][1][0]=transition_prob[state][1][2]+1\n",
    "    if state==2 or state==6 or state==16 or state==17 or state==22:\n",
    "        transition_prob[state][0][0]=transition_prob[state][0][2]-1\n",
    "        transition_prob[state][1][0]=transition_prob[state][1][2]+1\n",
    "    if state==3 or state == 18:\n",
    "        transition_prob[state][0][0]=transition_prob[state][0][2]-1\n",
    "        transition_prob[state][1][0]=transition_prob[state][1][2]+1\n",
    "        transition_prob[state][3][0]=transition_prob[state][3][2]+5\n",
    "    if state==5 or state==15:\n",
    "        transition_prob[state][2][0]=transition_prob[state][2][2]-5\n",
    "        transition_prob[state][1][0]=transition_prob[state][1][2]+1\n",
    "        transition_prob[state][3][0]=transition_prob[state][3][2]+5\n",
    "    if state==7:\n",
    "        transition_prob[state][0][0]=transition_prob[state][0][2]-1\n",
    "        transition_prob[state][3][0]=transition_prob[state][3][2]+5\n",
    "    if state==8 or state==10 or state==14:\n",
    "        transition_prob[state][2][0]=transition_prob[state][2][2]-5\n",
    "        transition_prob[state][3][0]=transition_prob[state][3][2]+5\n",
    "    if state==12 or state==23:\n",
    "        transition_prob[state][2][0]=transition_prob[state][2][2]-5\n",
    "        transition_prob[state][0][0]=transition_prob[state][0][2]-1\n",
    "        transition_prob[state][1][0]=transition_prob[state][1][2]+1\n",
    "    if state==13 or state==19:\n",
    "        transition_prob[state][2][0]=transition_prob[state][2][2]-5\n",
    "        transition_prob[state][0][0]=transition_prob[state][0][2]-1\n",
    "    if state==20:\n",
    "        transition_prob[state][2][0]=transition_prob[state][2][2]-5\n",
    "    if state==24:\n",
    "        transition_prob[state][0][0]=transition_prob[state][0][2]-1\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0004f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = np.zeros(100).reshape(25,4)+.25\n",
    "policy[4,:]=0\n",
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d1edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states = 25\n",
    "V= [0]*num_states\n",
    "V= [2*random.random() for x in V]\n",
    "gamma = .9\n",
    "theta = 0.01\n",
    "transition_prob \n",
    "\n",
    "def policy_evaluation(policy,gamma,theta,V,transition_prob):\n",
    "\n",
    "    while True:\n",
    "  \n",
    "        delta = 0\n",
    "        for state in range(len(policy)):\n",
    "            v= V[state]\n",
    "            if state==4:\n",
    "                V[state]=0\n",
    "            else:\n",
    "                V[state]=sum([(policy[state][actions]*(transition_prob[state][actions][1]+gamma*V[(transition_prob[state][actions][0])])) \n",
    "                              for actions in range(len(transition_prob[state]))])\n",
    "    \n",
    "            delta = max(delta,abs(v-V[state]))\n",
    "        if delta<theta:\n",
    "            break\n",
    "    return V\n",
    "\n",
    "def policy_improvement(policy,V,transition_prob,gamma):\n",
    "    policy_stable = True\n",
    "    for state in range(num_states):\n",
    "        \n",
    "        old_action = np.argmax(policy[state])\n",
    "        action_values = [(x[1]+gamma*V[x[0]]) for x in transition_prob[state]]\n",
    "        best_action = np.argmax(action_values)\n",
    "        new_policy = np.zeros(num_actions)\n",
    "        new_policy[best_action]=1\n",
    "        policy[state]=new_policy\n",
    "        if old_action != best_action:\n",
    "            policy_stable = False\n",
    "    return policy, policy_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63760caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy iteration\n",
    "while True:\n",
    "    V = policy_evaluation(policy,gamma,theta,V,transition_prob)\n",
    "    policy, policy_stable = policy_improvement(policy, V, transition_prob, gamma)\n",
    "    if policy_stable:\n",
    "        break\n",
    "\n",
    "print(\"Optimal value function:\", V)\n",
    "print(\"Optimal policy:\", policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5185ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_v = policy_evaluation(policy,gamma,theta,V,transition_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda91a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_array=np.array(V).reshape(5,5)\n",
    "sns.heatmap(v_array,annot=True,fmt='.2f',cbar=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a143d7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_array=np.array(V).reshape(5,5)\n",
    "sns.heatmap(v_array,annot=True,fmt='.2f',cbar=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aef39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b546b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3714b286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e706c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89a801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c799cc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a32793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d48ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4437ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c2567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f399da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2083674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b759dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize transition probabilities\n",
    "num_states = 25\n",
    "num_actions = 4\n",
    "transition_prob = np.zeros((num_states, num_actions, 4), dtype=int)\n",
    "\n",
    "# Set the transition probabilities for each state\n",
    "i = 0\n",
    "for state in range(num_states):\n",
    "    # Default assignments\n",
    "    transition_prob[state][:, 2] = i\n",
    "    transition_prob[state][:, 1] = -1  # Default reward\n",
    "    j = 0\n",
    "    \n",
    "    for action in transition_prob[state]:\n",
    "        action[3] = j  # Action index\n",
    "        if state == 4:\n",
    "            transition_prob[state][:, 1] = 0  # Zero reward for state 4\n",
    "        if state == 3 and action[3] == 1:\n",
    "            transition_prob[state][1, 1] = 0  # Specific condition for state 3, action 1\n",
    "        j += 1\n",
    "    \n",
    "    i += 1\n",
    "    transition_prob[state][:, 0] = transition_prob[state][:, 2]  # Set next state to current state index\n",
    "    \n",
    "    # Special transition rules\n",
    "    if state == 0 or state == 9:\n",
    "        transition_prob[state][3][0] = transition_prob[state][3][2] + 5\n",
    "    if state in [1, 11, 21]:\n",
    "        transition_prob[state][1][0] = transition_prob[state][1][2] + 1\n",
    "    if state in [2, 6, 16, 17, 22]:\n",
    "        transition_prob[state][0][0] = transition_prob[state][0][2] - 1\n",
    "        transition_prob[state][1][0] = transition_prob[state][1][2] + 1\n",
    "    if state == 3 or state == 18:\n",
    "        transition_prob[state][0][0] = transition_prob[state][0][2] - 1\n",
    "        transition_prob[state][1][0] = transition_prob[state][1][2] + 1\n",
    "        transition_prob[state][3][0] = transition_prob[state][3][2] + 5\n",
    "    if state in [5, 15]:\n",
    "        transition_prob[state][2][0] = transition_prob[state][2][2] - 5\n",
    "        transition_prob[state][1][0] = transition_prob[state][1][2] + 1\n",
    "        transition_prob[state][3][0] = transition_prob[state][3][2] + 5\n",
    "    if state == 7:\n",
    "        transition_prob[state][0][0] = transition_prob[state][0][2] - 1\n",
    "        transition_prob[state][3][0] = transition_prob[state][3][2] + 5\n",
    "    if state in [8, 10, 14]:\n",
    "        transition_prob[state][2][0] = transition_prob[state][2][2] - 5\n",
    "        transition_prob[state][3][0] = transition_prob[state][3][2] + 5\n",
    "    if state in [12, 23]:\n",
    "        transition_prob[state][2][0] = transition_prob[state][2][2] - 5\n",
    "        transition_prob[state][0][0] = transition_prob[state][0][2] - 1\n",
    "        transition_prob[state][1][0] = transition_prob[state][1][2] + 1\n",
    "    if state in [13, 19]:\n",
    "        transition_prob[state][2][0] = transition_prob[state][2][2] - 5\n",
    "        transition_prob[state][0][0] = transition_prob[state][0][2] - 1\n",
    "    if state == 20:\n",
    "        transition_prob[state][2][0] = transition_prob[state][2][2] - 5\n",
    "    if state == 24:\n",
    "        transition_prob[state][0][0] = transition_prob[state][0][2] - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51116903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define number of states and initialize value function\n",
    "num_states = 25\n",
    "num_actions = 4\n",
    "V = np.random.rand(num_states) * 2  # Initialize V with random values between 0 and 2\n",
    "\n",
    "# Define gamma (discount factor) and theta (threshold for stopping criteria)\n",
    "gamma = 0.9\n",
    "theta = 0.001\n",
    "\n",
    "# Initialize policy with equal probabilities for each action\n",
    "policy = np.ones((num_states, num_actions)) / num_actions\n",
    "\n",
    "def policy_evaluation(policy, gamma, theta, V, transition_prob):\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for state in range(num_states):\n",
    "            v = V[state]\n",
    "            if state == 4:\n",
    "                V[state] = 0\n",
    "            else:\n",
    "                V[state] = sum(\n",
    "                    policy[state][action] * (reward + gamma * V[next_state])\n",
    "                    for action, (next_state, reward, _, _) in enumerate(transition_prob[state])\n",
    "                )\n",
    "            delta = max(delta, abs(v - V[state]))\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return V\n",
    "\n",
    "def policy_improvement(policy, V, transition_prob, gamma):\n",
    "    policy_stable = True\n",
    "    for state in range(num_states):\n",
    "        old_action = np.argmax(policy[state])\n",
    "        action_values = [\n",
    "            reward + gamma * V[next_state]\n",
    "            for next_state, reward, _, _ in transition_prob[state]\n",
    "        ]\n",
    "        best_action = np.argmax(action_values)\n",
    "        policy[state] = np.eye(num_actions)[best_action]\n",
    "        if old_action != best_action:\n",
    "            policy_stable = False\n",
    "    return policy, policy_stable\n",
    "\n",
    "# Example of running policy iteration\n",
    "V = policy_evaluation(policy, gamma, theta, V, transition_prob)\n",
    "policy, policy_stable = policy_improvement(policy, V, transition_prob, gamma)\n",
    "\n",
    "print(f\"Value Function: {V}\")\n",
    "print(f\"Policy Stable: {policy_stable}\")\n",
    "print(f\"Policy: {policy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_array=np.array(V).reshape(5,5)\n",
    "sns.heatmap(v_array,annot=True,fmt='.2f',cbar=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bb58fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e723e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define number of states and initialize value function\n",
    "num_states = 25\n",
    "num_actions = 4\n",
    "V = np.random.rand(num_states) * 2  # Initialize V with random values between 0 and 2\n",
    "\n",
    "# Define gamma (discount factor) and theta (threshold for stopping criteria)\n",
    "gamma = 0.9\n",
    "theta = 0.01\n",
    "\n",
    "# Initialize policy with equal probabilities for each action\n",
    "policy = np.ones((num_states, num_actions)) / num_actions\n",
    "\n",
    "def policy_evaluation(policy, gamma, theta, V, transition_prob):\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for state in range(num_states):\n",
    "            v = V[state]\n",
    "            if state == 4:\n",
    "                V[state] = 0\n",
    "            else:\n",
    "                V[state] = sum(\n",
    "                    policy[state][action] * (reward + gamma * V[next_state])\n",
    "                    for action, (next_state, reward, _, _) in enumerate(transition_prob[state])\n",
    "                )\n",
    "            delta = max(delta, abs(v - V[state]))\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return V\n",
    "\n",
    "def policy_improvement(policy, V, transition_prob, gamma):\n",
    "    policy_stable = True\n",
    "    for state in range(num_states):\n",
    "        old_action = np.argmax(policy[state])\n",
    "        action_values = [\n",
    "            reward + gamma * V[next_state]\n",
    "            for next_state, reward, _, _ in transition_prob[state]\n",
    "        ]\n",
    "        best_action = np.argmax(action_values)\n",
    "        # Create a new deterministic policy for this state\n",
    "        new_policy = np.zeros(num_actions)\n",
    "        new_policy[best_action] = 1.0\n",
    "        policy[state] = new_policy\n",
    "        if old_action != best_action:\n",
    "            policy_stable = False\n",
    "    return policy, policy_stable\n",
    "\n",
    "# Run policy iteration\n",
    "policy_stable = False\n",
    "while not policy_stable:\n",
    "    V = policy_evaluation(policy, gamma, theta, V, transition_prob)\n",
    "    policy, policy_stable = policy_improvement(policy, V, transition_prob, gamma)\n",
    "\n",
    "print(f\"Value Function: {V}\")\n",
    "print(f\"Policy Stable: {policy_stable}\")\n",
    "print(f\"Optimal Policy: {policy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7dc2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_array=np.array(V).reshape(5,5)\n",
    "sns.heatmap(v_array,annot=True,fmt='.2f',cbar=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae9536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964f9514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b5bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for action, (next_state, reward, _, _) in enumerate(transition_prob[state]):\n",
    "    print((next_state, reward, _, _))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7accd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
